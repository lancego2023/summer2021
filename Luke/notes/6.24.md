## Tasks Completed

- Researched Prometheus - this could be a promising solution to retrieve the metrics from the device in real time
- Put work towards a Python script that could do the following:
  - Run the Docker container of the target app
  - Run tegrastats and pycuda in a background thread to log in real time the GPU metrics from the app
  - (OPTIONAL) Run nvprof in the background and collect stats for when it is complete

## Notes

- Yongho said that there will be a dedicated Jenkins pipeline for profiling, so I am working on understanding Jenkins and will see if I can make a simple pipeline that will run by GPU profiling script
  - I am going to take a break from learning Jenkins because if Yomi can cover the process of building the pipeline, then I don't need to know the details of its operation
- I will need to understand which GPU metrics are most relevant to capture, which means I need to understand how a GPU is layed out at the general architecture level.
  - Hierarchy of thread groups
    - Thread blocks synchronize with each other and have a share memory
  - Share memories
  - Barrier synchronization
- Chris and I will also need to configure a method to report the metrics gathered by Tau and nvprof. Prometheus might be a promising solution to gathering metrics from the testbed.
  - Is it possible to run prometheus and the test app within the same Docker container?
- Sean's Plugin Development Meeting
  - Got a hands-on explanation of how to implement an app

